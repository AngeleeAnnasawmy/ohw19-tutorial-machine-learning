{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D Convolutional Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to run a simple deep learning model to classify whale calls. We use the [keras](https://keras.io/) library. We will use a convolutional neural networks, since they are robust to temporal and spatial shifts. Although it is common to use 2D convolutional neural networks when working with spectrogram, we will use a 1D on the time series, as this can be applied to other time series classification problems. But instead of raw data, we will use the power spectrum profile of each signal and we hope that they will be sufficiently different for signals which contain right whale calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing multiple visualization libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import mlab\n",
    "import pylab as pl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries to manipulate the data files\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a library to read the .aiff sound format\n",
    "import aifc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the filenames\n",
    "filenames = sorted(glob(os.path.join('data','train','*.aiff')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the power spectrum for each signal (which will be a one dimensional object). We can calculate tit using the [welch filter](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.welch.html#scipy.signal.welch) from the `scipy.signal` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read signals and apply the welch filter\n",
    "feature_dict = {}\n",
    "fs = 2000\n",
    "for filename in filenames[:10000]:\n",
    "    aiff = aifc.open(filename,'r')\n",
    "    whale_strSig = aiff.readframes(aiff.getnframes())\n",
    "    whale_array = np.fromstring(whale_strSig, np.short).byteswap()\n",
    "    # apply welch filter\n",
    "    feature = 10*np.log10(signal.welch(whale_array, fs=fs, window='hanning', nperseg=256, noverlap=128+64)[1])\n",
    "    feature_dict[filename] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an example of power spectrum\n",
    "plt.plot(feature_dict['data/train/train00006.aiff'])\n",
    "plt.title('Power Spectrum for a Right Whale Up-call')\n",
    "plt.ylabel('Power Spectrum')\n",
    "plt.xlabel('Time in Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = np.array(labels['label'][X.columns])\n",
    "y = np.load('y.npy')\n",
    "y = y.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(feature_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries for Deep Learning on Time Domain Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training - Validation Dataset Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2018, shuffle=True)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_val = np.expand_dims(X_val, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 3, activation='relu', input_shape=(129, 1)))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jargon Translation:**\n",
    "\n",
    "|Term| Explanation|\n",
    "|---|---|\n",
    "|Convolutional Layers | layers which are robust to time shifts|\n",
    "|Max Pooling/ Average Pooling |dimension reduction, robustness|\n",
    "|Batch normalization |equalizes the distribution of the batches |\n",
    "|Epochs |1 run of a batch |\n",
    "|Adam Optimizer | an adaptive optimization scheme|\n",
    "|Cross Entropy | cost function|\n",
    "|ReLU | nonlinear activation function| \n",
    "|Batch Size| size of subset to process to update the estimates|\n",
    "|Learning Rate | time step of the optimization algorithm|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the Computation Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model,to_file='model_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/model_plot.png\" width=200/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Logging Object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deep_1'\n",
    "top_weights_path = 'model_' + str(model_name) + '.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(top_weights_path, monitor = 'val_acc', verbose = 1, save_best_only = True, save_weights_only = True), \n",
    "    EarlyStopping(monitor = 'val_acc', patience = 6, verbose = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, patience = 3, verbose = 1),\n",
    "    CSVLogger('model_' + str(model_name) + '.log')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fitting the Model(this will take loooooooong time, if run on CPU)\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data = [X_val, y_val], callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate(X_val, y_val, batch_size=16)\n",
    "print('Validation accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction and prediction scores\n",
    "y_pred = np.array((model.predict(X_val)>0.5).astype('int32'))\n",
    "y_score = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "print('Validation precision:', sum(y_pred[y_val == 1]>0)/sum(y_pred == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall\n",
    "print('Validation recall:', sum(y_pred[y_val == 1]>0)/sum(y_val == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_val,y_pred)\n",
    "# Transform to df for easier plotting\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['No_Upcall','Upcall'], \n",
    "                     columns = ['No_Upcall','Upcall'])\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm_df, annot=True, fmt='g')\n",
    "plt.title('\\nAccuracy:{0:.3f}'.format(accuracy_score(y_val, y_pred)))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Prediction Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, roc_curve \n",
    "roc_auc = roc_auc_score(y_val.astype('int'), y_score)\n",
    "fpr, tpr, _ = roc_curve(y_val, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate\\n predicted upcall when no upcall')\n",
    "plt.ylabel('True Positive Rate\\n predicted upcall when upcall')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_val.astype('int'), y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Prediction and Recall\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_val.astype('int'), y_score)\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More:** \n",
    "\n",
    "* Data Augmentation: [Image Data Generators](https://keras.io/preprocessing/image/) \n",
    "* Transfer Learning: [blog](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a), [example](https://www.kaggle.com/valcoder/whalesounds-dl-2d/)\n",
    "* 2D Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "\n",
    "[Deep Learning Glossary](http://www.wildml.com/deep-learning-glossary/)\n",
    "\n",
    "[Keras and NN Tutorial](https://indico.cern.ch/event/506145/contributions/2132944/attachments/1258124/1858154/NNinKeras_MPaganini.pdf)\n",
    "\n",
    "[Keras Cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf)\n",
    "\n",
    "Free GPU usage: [Google Colaboratory notebooks](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true) & [Kaggle Kernels](https://www.kaggle.com/kernels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring Performance: [TensorBoard](https://www.tensorflow.org/guide/summaries_and_tensorboard), [TensorWatch](https://github.com/microsoft/tensorwatch/blob/master/README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
